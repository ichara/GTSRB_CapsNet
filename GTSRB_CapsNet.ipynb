{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GTSRB_CapsNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ichara/GTSRB_CapsNet/blob/master/GTSRB_CapsNet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "stbD1s1mCYG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data: [Keras Tutorial - Traffic Sign Recognition](https://chsasank.github.io/keras-tutorial.html),  \n",
        "Model: [keras/examples/cifar10_cnn_capsule.py](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn_capsule.py) + Conv2Ds, Denses, etc.\n",
        "\n",
        "For TensorFlow backend\n"
      ]
    },
    {
      "metadata": {
        "id": "UVe1hzi6CYG4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import color, exposure, transform\n",
        "\n",
        "NUM_CLASSES = 43\n",
        "IMG_SIZE = 48\n",
        "\n",
        "def preprocess_img(img):\n",
        "    # Histogram normalization in v channel\n",
        "    hsv = color.rgb2hsv(img)\n",
        "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
        "    img = color.hsv2rgb(hsv)\n",
        "\n",
        "    # central square(* 0.9) crop\n",
        "    min_side = min(img.shape[:-1]) * 9 // 10 # Added\n",
        "    centre = img.shape[0] // 2, img.shape[1] // 2\n",
        "    img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,\n",
        "              centre[1] - min_side // 2:centre[1] + min_side // 2,\n",
        "              :]\n",
        "\n",
        "    # rescale to standard size\n",
        "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2wkn4lACYG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "23d13f47-9fea-44e2-aa61-6703a3f44a09"
      },
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def get_class(img_path):\n",
        "    return int(img_path.split('/')[-2])\n",
        "\n",
        "# root_dir = 'GTSRB/Final_Training/Images/'\n",
        "root_dir = 'GTSRB/Final_Training/Images/'\n",
        "imgs = []\n",
        "labels = []\n",
        "\n",
        "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
        "np.random.shuffle(all_img_paths)\n",
        "for img_path in all_img_paths:\n",
        "    img_path = img_path.replace('\\\\', '/') # Added for Windows OS\n",
        "    img = preprocess_img(io.imread(img_path))\n",
        "    label = get_class(img_path)\n",
        "    imgs.append(img)\n",
        "    labels.append(label)\n",
        "\n",
        "X = np.array(imgs, dtype='float32')\n",
        "# Make one hot targets\n",
        "Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AWyP3NbDCYG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "30676b79-23ed-4658-88bb-7542b65ba831"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('GTSRB/GT-final_test.csv', sep=';')\n",
        "\n",
        "# Load test dataset\n",
        "X_test = []\n",
        "y_test = []\n",
        "i = 0\n",
        "for file_name, class_id in zip(list(test['Filename']), list(test['ClassId'])):\n",
        "    img_path = os.path.join('GTSRB/Final_Test/Images/', file_name)\n",
        "    X_test.append(preprocess_img(io.imread(img_path)))\n",
        "    y_test.append(class_id)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "7QCnpLDuCYHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dc01d48a-0edb-4ac2-de6a-5d09d9182ab5"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import activations\n",
        "from keras import utils\n",
        "# from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# the squashing function.\n",
        "# we use 0.5 in stead of 1 in hinton's paper.\n",
        "# if 1, the norm of vector will be zoomed out.\n",
        "# if 0.5, the norm will be zoomed in while original norm is less than 0.5\n",
        "# and be zoomed out while original norm is greater than 0.5.\n",
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "\n",
        "# define our own softmax function instead of K.softmax\n",
        "# because K.softmax can not specify axis.\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "# define the margin loss like hinge loss\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "\n",
        "class Capsule(Layer):\n",
        "    \"\"\"A Capsule Implement with Pure Keras\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "\n",
        "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
        "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "\n",
        "        This change can improve the feature representation of Capsule.\n",
        "\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            if K.backend() == 'theano':\n",
        "                o = K.sum(o, axis=1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FeHxYyGLCYHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tflog_num = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hydeTWh-CYHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for TensorBoard\n",
        "import keras.callbacks\n",
        "import keras.backend.tensorflow_backend as KTF\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "session = tf.Session('')\n",
        "KTF.set_session(session)\n",
        "\n",
        "tflog_num += 1\n",
        "tb_cb = keras.callbacks.TensorBoard(log_dir='tflog' + str(tflog_num), histogram_freq=1)\n",
        "cbks = [tb_cb]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_aXJu2lCYHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "a0ff28cf-91a5-4c24-fa0c-f7123ac0aea3"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = NUM_CLASSES\n",
        "num_dims = 16\n",
        "\n",
        "K.set_image_dim_ordering('tf')\n",
        "\n",
        "# A common Conv2D model\n",
        "input_image = Input(shape=(None, None, 3))\n",
        "x = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "\n",
        "\"\"\"now we reshape it as (batch_size, input_num_capsule, input_dim_capsule)\n",
        "then connect a Capsule layer.\n",
        "\n",
        "the output of final model is the lengths of 10 Capsule, whose dim=16.\n",
        "\n",
        "the length of Capsule is the proba,\n",
        "so the problem becomes a 10 two-classification problem.\n",
        "\"\"\"\n",
        "\n",
        "x = Reshape((-1, 256))(x)\n",
        "capsule = Capsule(num_classes, num_dims, 3, True)(x)\n",
        "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
        "output = Dense(256)(output)\n",
        "output = Dropout(0.5)(output)\n",
        "output = Dense(43)(output)\n",
        "model = Model(inputs=input_image, outputs=output)\n",
        "\n",
        "# we use a margin loss\n",
        "adam = keras.optimizers.Adam(lr=0.0001); # Added: 0.001 -> 0.0001\n",
        "model.compile(loss=margin_loss, optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "capsule_1 (Capsule)          (None, 43, 16)            176128    \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 43)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               11264     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 43)                11051     \n",
            "=================================================================\n",
            "Total params: 1,344,619\n",
            "Trainable params: 1,344,235\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z1r1VkH5CYHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "9f6eaa6b-f8b9-4bdb-c254-f18fe71b2dbe"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by dataset std\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=10,  # randomly rotate images in 0 to 180 degrees\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally\n",
        "    height_shift_range=0.1,  # randomly shift images vertically\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False,  # randomly flip images\n",
        "    zoom_range=[0.9, 1.1],\n",
        "    shear_range=0.1\n",
        "    )\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(\n",
        "    datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    # callbacks=cbks, # for TensorBoard\n",
        "    validation_data=(X_val, Y_val),\n",
        "    workers=4)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "491/491 [==============================] - 52s 105ms/step - loss: 0.5587 - acc: 0.2826 - val_loss: 0.2931 - val_acc: 0.6517\n",
            "Epoch 2/15\n",
            "234/491 [=============>................] - ETA: 24s - loss: 0.2940 - acc: 0.6614"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 99ms/step - loss: 0.2322 - acc: 0.7475 - val_loss: 0.0728 - val_acc: 0.9308\n",
            "Epoch 3/15\n",
            "362/491 [=====================>........] - ETA: 11s - loss: 0.0952 - acc: 0.9246"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 48s 98ms/step - loss: 0.0879 - acc: 0.9322 - val_loss: 0.0238 - val_acc: 0.9807\n",
            "Epoch 4/15\n",
            "408/491 [=======================>......] - ETA: 7s - loss: 0.0492 - acc: 0.9692\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 99ms/step - loss: 0.0475 - acc: 0.9703 - val_loss: 0.0113 - val_acc: 0.9902\n",
            "Epoch 5/15\n",
            "428/491 [=========================>....] - ETA: 5s - loss: 0.0299 - acc: 0.9831"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 48s 98ms/step - loss: 0.0295 - acc: 0.9833 - val_loss: 0.0111 - val_acc: 0.9901\n",
            "Epoch 6/15\n",
            "430/491 [=========================>....] - ETA: 5s - loss: 0.0225 - acc: 0.9872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 48s 98ms/step - loss: 0.0223 - acc: 0.9873 - val_loss: 0.0061 - val_acc: 0.9941\n",
            "Epoch 7/15\n",
            "430/491 [=========================>....] - ETA: 5s - loss: 0.0171 - acc: 0.9905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 99ms/step - loss: 0.0166 - acc: 0.9909 - val_loss: 0.0073 - val_acc: 0.9934\n",
            "Epoch 8/15\n",
            "438/491 [=========================>....] - ETA: 4s - loss: 0.0131 - acc: 0.9927"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 48s 97ms/step - loss: 0.0130 - acc: 0.9928 - val_loss: 0.0048 - val_acc: 0.9959\n",
            "Epoch 9/15\n",
            "433/491 [=========================>....] - ETA: 5s - loss: 0.0110 - acc: 0.9936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 100ms/step - loss: 0.0109 - acc: 0.9936 - val_loss: 0.0054 - val_acc: 0.9950\n",
            "Epoch 10/15\n",
            "430/491 [=========================>....] - ETA: 5s - loss: 0.0107 - acc: 0.9938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 99ms/step - loss: 0.0104 - acc: 0.9940 - val_loss: 0.0056 - val_acc: 0.9939\n",
            "Epoch 11/15\n",
            "432/491 [=========================>....] - ETA: 5s - loss: 0.0085 - acc: 0.9952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 100ms/step - loss: 0.0084 - acc: 0.9952 - val_loss: 0.0036 - val_acc: 0.9971\n",
            "Epoch 12/15\n",
            "436/491 [=========================>....] - ETA: 5s - loss: 0.0066 - acc: 0.9963"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 48s 98ms/step - loss: 0.0065 - acc: 0.9964 - val_loss: 0.0041 - val_acc: 0.9972\n",
            "Epoch 13/15\n",
            "434/491 [=========================>....] - ETA: 5s - loss: 0.0073 - acc: 0.9955"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 48s 98ms/step - loss: 0.0072 - acc: 0.9956 - val_loss: 0.0024 - val_acc: 0.9978\n",
            "Epoch 14/15\n",
            "425/491 [========================>.....] - ETA: 6s - loss: 0.0049 - acc: 0.9974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 100ms/step - loss: 0.0050 - acc: 0.9972 - val_loss: 0.0071 - val_acc: 0.9926\n",
            "Epoch 15/15\n",
            "429/491 [=========================>....]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "491/491 [==============================] - 49s 100ms/step - loss: 0.0063 - acc: 0.9962 - val_loss: 0.0029 - val_acc: 0.9976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f18dd093c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "G7u6e8e6CYHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f9d724ae-f3cc-4a9a-c8a7-febff2eb787a"
      },
      "cell_type": "code",
      "source": [
        "# predict and evaluate\n",
        "y_proba = model.predict(X_test)\n",
        "y_pred = y_proba.argmax(axis=-1)\n",
        "acc = np.sum(y_pred == y_test) / np.size(y_pred)\n",
        "print(\"Test accuracy = {}\".format(acc))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy = 0.9832937450514647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Wc0fpIvCYHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# format for TSR-Analysis: 00000.ppm;16\n",
        "np.savetxt('y_pred_' + str(tflog_num) + '.csv', \n",
        "           np.column_stack((np.arange(len(y_pred)), y_pred)), fmt='%05d.ppm;%.0f')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}